import numpy as np
from PIL import Image
import math

def read_image(filename, max_dim= -1):
    """Read image and rescale to specified max dimension (if exists)

    Args:
        filename: image input file path string
        max_dim: max dimension to scale down the image; keep original size if -1

    Returns:
        Tuple of scaled image along with original image height and width
    """
    image = Image.open(filename)
    # scale 0~255 to 0~1
    np_image = np.array(image, dtype=np.float32) / 255.0
    return np_image

def read_cam_file(filename):
    with open(filename) as f:
        lines = [line.rstrip() for line in f.readlines()]
    # extrinsics: line [1,5), 4x4 matrix
    extrinsics = np.fromstring(' '.join(lines[1:5]), dtype=np.float32, sep=' ').reshape((4, 4))
    # intrinsics: line [7-10), 3x3 matrix
    intrinsics = np.fromstring(' '.join(lines[7:10]), dtype=np.float32, sep=' ').reshape((3, 3))
    # depth min and max: line 11
    if len(lines) >= 12:
        depth_params = np.fromstring(lines[11], dtype=np.float32, sep=' ')
    else:
        depth_params = np.empty(0)

    return intrinsics, extrinsics, depth_params

def project_points(points_3d, colors, K, RT):
    points_cam = RT @ np.hstack((points_3d, np.ones((len(points_3d), 1)))).T
    points_proj = K @ points_cam
    points_proj = points_proj[:2, :] / points_proj[2, :]
    return points_proj, colors

def focal2fov(focal, pixels):
    return 2 * math.atan(pixels / (2 * focal))

def frustrum_clean(pcd, color, intrinsic, extrinsic, W_ori):
    center = np.ones((4, 1))
    c = intrinsic[:2, 2][:,np.newaxis]
    center[:2] = c
    pose = np.linalg.inv(extrinsic)
    cam_ori = pose[:3, 3:]

    world_cam_center = (pose @ np.linalg.inv(intrinsic) @ center)[:3]
    view_dir = np.repeat((world_cam_center - cam_ori).transpose((1,0)), pcd.shape[0], axis=0)
    view_dir = view_dir / np.linalg.norm(view_dir, axis=1, keepdims=True)
    point_dirs = pcd - cam_ori.reshape(-1)
    point_dirs = point_dirs / np.linalg.norm(point_dirs, axis=1, keepdims=True)

    angles = np.arccos(np.sum(point_dirs * view_dir, axis=-1))

    fov = focal2fov(intrinsic[0, 0], W_ori) / 2
    filtered_indices = np.where((angles < fov))
    filtered_points = pcd[filtered_indices]
    color_points = color[filtered_indices]
    return filtered_points, color_points


T = np.array([[1,0,0,0],
            [0,-1,0,0],
            [0,0,-1,0],
            [0,0,0,1]])

def prepare_depth(depth):
    # adjust depth maps generated by vision blender
    INVALID_DEPTH = -1
    depth[depth == INVALID_DEPTH] = 0
    return depth

def find_depth(npz_file):
    npz = np.load(npz_file, allow_pickle=True)
    depth = npz['depth_map']
    depth = prepare_depth(depth)
    return depth

def find_pose(npz_file):
    npz = np.load(npz_file, allow_pickle=True)
    poses = npz['object_poses']
    for obj in poses:
        obj_name = obj['name']
        obj_mat = obj['pose']
        if obj_name == 'Camera':
            pose = obj_mat.astype(np.float32)
            break
    return pose @ T



